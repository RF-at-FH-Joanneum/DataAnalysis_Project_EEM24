{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Assignment 4\n",
    "**Group: Ohm_Squad**\n",
    "\n",
    "**Members: Rauch,Bilijesko,Frizberg**\n",
    "\n",
    "**Datasets: Westermo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [12, 8],\n",
    "    'figure.dpi': 150,\n",
    "    'figure.autolayout': True,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "pathRaw = \"./data_raw/\"\n",
    "pathFilter = \"./data_filtered/\"\n",
    "pathProcessd = \"./data_processed/\"\n",
    "pathVisuRaw = \"./visu_raw/\"\n",
    "\n",
    "files = [f\"system-{number}.csv\" for number in range(1, 20)]\n",
    "\n",
    "# Systems 3, 5, 6, 8, 11 and 17 do not have sys-thermal readings ! 3/5/6 -> crashes 8/11/17 -> no thermal\n",
    "remove_entries = [7,10,16]\n",
    "files = [item for index, item in enumerate(files) if index not in remove_entries]\n",
    "files = files [0:2]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Filtering\n",
    "Files are fetched from directory and prefiltering for columns of interst.\n",
    "\n",
    "Processing timestamps to datetime for usage in timeseries (and usability).\n",
    "\n",
    "Done via a function to execute for every file separately and be able to pipe if necessary.\n",
    "\n",
    "Returning the dataframe could be either dropped or caught by either a container or piped into the next function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_system_data(file_dir: str, file_name: str) -> pd.DataFrame :\n",
    "    \"\"\"Load and prepare test system performance data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_dir : str\n",
    "        Path to the CSV data file location (directory)\n",
    "    file_name : str\n",
    "        Name of the specified CSV file\n",
    "    \n",
    "    Additional outputs\n",
    "    saves filtered data into dir \"./data_filtered\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Raw dataframe with columns:\n",
    "        - datetime (index)\n",
    "        - load-15m\n",
    "        - memory_used_pct\n",
    "        - cpu-user\n",
    "        - cpu-system\n",
    "        - sys-thermal\n",
    "        - sys-interrupt-rate\n",
    "        - server-up\n",
    "        - disk-io-time\n",
    "    \"\"\"\n",
    "    file_path = file_dir + file_name\n",
    "\n",
    "    df = pd.read_csv(file_path, delimiter = \",\",usecols=[\"timestamp\",\n",
    "                                                         \"load-15m\",\n",
    "                                                         \"sys-mem-available\",\n",
    "                                                         \"sys-mem-total\",\n",
    "                                                         \"cpu-user\",\n",
    "                                                         \"cpu-system\",\n",
    "                                                         \"sys-thermal\",\n",
    "                                                         \"sys-interrupt-rate\",\n",
    "                                                         \"server-up\",\n",
    "                                                         \"disk-io-time\"]) # Read in data with columns\n",
    "    \n",
    "\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit = 's', errors = 'coerce') # Create datetime from timestamp\n",
    "    \n",
    "    df.set_index('datetime', inplace=True) # Set datetime as index\n",
    "\n",
    "    df['memory_used_pct'] = (1 - df['sys-mem-available']/df['sys-mem-total']) * 100 # Memory usage calculation\n",
    "    df.drop([\"timestamp\",\"sys-mem-available\",\"sys-mem-total\"], axis=1, inplace=True) # Drop unneccessary data\n",
    "    \n",
    "    df.to_csv(pathFilter+file_name, index=True)\n",
    "    \n",
    "    df.describe().to_csv(f'{pathVisuRaw}{file_name}_desciption.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# testing df = load_system_data(pathRaw,\"system-3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    this = load_system_data(pathRaw, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Raw\n",
    "\n",
    "First: Heler functions for interacting with images and os to delete temporary files.\n",
    "\n",
    "Second: Main function for visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted https://stackoverflow.com/questions/6996603/how-can-i-delete-a-file-or-folder-in-python\n",
    "def delete_images(files: list[str]):\n",
    "    \"\"\"Deletes the files specified in the list of file paths.\n",
    "    Parameters\n",
    "    ----------\n",
    "    files: list[str]\n",
    "        List of names of image files to put into .pdf file. \n",
    "    \n",
    "    Additional output\n",
    "    ----------\n",
    "        Deltes list of images.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            if os.path.exists(file):\n",
    "                os.remove(file)\n",
    "                #print(f\"Deleted: {file}\")\n",
    "            else:\n",
    "                print(f\"File not found: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "            \n",
    "# adapted https://stackoverflow.com/questions/40906463/png-images-to-one-pdf-in-python \n",
    "# and https://www.geeksforgeeks.org/save-multiple-matplotlib-figures-in-single-pdf-file-using-python/ \n",
    "def save_image(image_names: list[str], out_dir: str, filename: str): \n",
    "    \"\"\"Gathers multiple plt.figure obejcts and outputs thm into a pdf \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_names: list[str]\n",
    "        List of names of image files to put into .pdf file   \n",
    "    out_dir: str\n",
    "        Path to the directory of output .pdf file\n",
    "    filename: str\n",
    "        Name of output .pdf file\n",
    "        \n",
    "    Additional output\n",
    "    ----------\n",
    "        Saves a .pdf created by multiple .pngs into specified directory\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    image_list = [] #contains opened files\n",
    "    for name in image_names:\n",
    "        print(name)\n",
    "        image_list.append(Image.open(name))\n",
    "\n",
    "    image_list[0].save(f\"{out_dir}{filename}.pdf\", save_all=True, append_images=image_list[1:])\n",
    "    for image in image_list:\n",
    "        image.close()\n",
    "    print(f\"{out_dir}{filename}_allPlots.pdf\")\n",
    "    delete_images(image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visu_raw_data(show_plots: bool, file_dir: str, file_name: str, df_arg: pd.DataFrame = None):\n",
    "    \"\"\"Load and visualize filtered test system performance data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    show_plots: bool\n",
    "        Just output files or display in notebook\n",
    "    file_dir : str\n",
    "        Path to the CSV data file location (directory)\n",
    "    file_name : str\n",
    "        Name of the specified CSV file\n",
    "    \n",
    "    \n",
    "    optional\n",
    "    df_arg: pd.DataFrame\n",
    "        output from load_system_data()\n",
    "\n",
    "    Additional outputs\n",
    "    saves visualized data into dir \"./visu_raw\" by calling save_image() and cleaning temp-files with delete_images()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check DataFrame was passed\n",
    "    if isinstance(df_arg, pd.DataFrame):\n",
    "        df = df_arg\n",
    "        # File name and path -> pd used => no identifier => using \"./\" \n",
    "        out_dir = \"./\"\n",
    "        out_name = \"Visu_output_noident\"\n",
    "        print(\"Function called with a DataFrame.\")\n",
    "    else:\n",
    "        # Attempt to read the DataFrame from file\n",
    "        try:\n",
    "            file_path = file_dir + file_name\n",
    "            df = pd.read_csv(file_path, delimiter = \",\",usecols=[\"datetime\",\"load-15m\",\"memory_used_pct\",\"cpu-user\",\"cpu-system\",\"sys-thermal\",\"sys-interrupt-rate\",\"server-up\",\"disk-io-time\"])\n",
    "            print(f\"Function called with a file: {file_path}\")\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df.set_index('datetime', inplace=True)\n",
    "            # File name and path -> path used => use identifier \n",
    "            out_dir = pathVisuRaw\n",
    "            out_name = file_name.replace('.csv', '')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the file: {e}\")\n",
    "            return None\n",
    "    measurements = {\n",
    "        \"load-15m\": ('load-15m', '%'),\n",
    "        \"memory_used_pct\": ('memory_used_pct', '%'),\n",
    "        \"cpu-user\": ('cpu-user', 'delta-s'),\n",
    "        \"cpu-system\": ('cpu-system', 'delta-s'),\n",
    "        \"sys-thermal\": ('sys-thermal', 'avg delta-°C/min'),\n",
    "        \"sys-interrupt-rate\": ('sys-interrupt-rate', 'delta-s'),\n",
    "        \"disk-io-time\": ('disk-io-time', 'delta-s')\n",
    "        #,\"server-up\": ('server-sup', '')\n",
    "    }\n",
    "    image_names = []\n",
    "    image_nr = 0\n",
    "    \n",
    "    # Plot 1: Time-Series\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(15, 30))\n",
    "    fig.suptitle('Tme-Series - Raw Data', fontsize=16, y=1.02)\n",
    "\n",
    "    for i,(measure, (title, unit)) in enumerate(measurements.items()):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "\n",
    "        df.iloc[::10].pivot(columns='server-up', values=measure).plot(\n",
    "            ax=axes[row, col],\n",
    "            legend=True, \n",
    "            alpha=0.7, \n",
    "            linewidth=2,\n",
    "            color=['red','blue'],\n",
    "            xlabel='Datetime',\n",
    "            ylabel=f'{title} ({unit})',\n",
    "            title=f'Time-Series of {measure.upper()}'\n",
    "        )\n",
    "\n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    # Plot 2: Daily Patterns\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(15, 30))\n",
    "    fig.suptitle('Daily Patterns of Raw Measurements - mean & std ', fontsize=16, y=1.02)\n",
    "\n",
    "    # Create hour column for grouping\n",
    "    df_hour = df.copy()\n",
    "    df_hour['hour'] = df_hour.index.hour\n",
    "\n",
    "    \n",
    "    for i, measurement in enumerate(measurements):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        # Calculate hourly statistics\n",
    "        hourly_stats = df_hour.groupby('hour')[measurement].agg(['mean', 'std'])\n",
    "        \n",
    "        # Plot mean with standard deviation\n",
    "        axes[row, col].plot(hourly_stats.index, hourly_stats['mean'], \n",
    "                        'b-', label='Mean')\n",
    "        axes[row, col].fill_between(\n",
    "            hourly_stats.index,\n",
    "            hourly_stats['mean'] - hourly_stats['std'],\n",
    "            hourly_stats['mean'] + hourly_stats['std'],\n",
    "            alpha=0.2,\n",
    "            label='±1 std'\n",
    "        )\n",
    "        \n",
    "        axes[row, col].set_title(f'Daily {measurement.capitalize()} Pattern')\n",
    "        axes[row, col].set_xlabel('Hour of Day')\n",
    "        axes[row, col].set_ylabel(measurement)\n",
    "        axes[row, col].grid(True)\n",
    "        axes[row, col].legend()\n",
    "\n",
    "\n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "\n",
    "    # Plot 3: Hour-wise Distributions\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(15, 30))\n",
    "    fig.suptitle('Measurement Distributions by Hour - Boxplots', fontsize=16, y=1.02)\n",
    "        \n",
    "    for i,(measure, (title, unit)) in enumerate(measurements.items()):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        df_hour.boxplot(\n",
    "            ax=axes[row, col],\n",
    "            column=measure,\n",
    "            by='hour'\n",
    "        )\n",
    "        axes[row, col].set_title(f'Daily Pattern of {title} ')\n",
    "        axes[row, col].set_xlabel('Hour of Day')\n",
    "        axes[row, col].set_ylabel(f'{title} ({unit})')\n",
    "        axes[row, col].grid(True)\n",
    "\n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "\n",
    "    # Plot 4 Histograms - Distribution\n",
    "    fig, axes = plt.subplots(4,2, figsize = (15, 12))\n",
    "    fig.suptitle('Sensor Raw Measurements Distributions', fontsize = 14)\n",
    "\n",
    "    for i,(measure, (title, unit)) in enumerate(measurements.items()):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        bin_num = 150\n",
    "        axes[row, col].hist(df[measure], bins = bin_num, density = True, alpha = 0.7)\n",
    "\n",
    "        counts, bins = np.histogram(df[measure], bins = bin_num)\n",
    "        bin_centers = (bins[:-1] + bins [1:]) / 2\n",
    "        axes[row, col].plot(bin_centers, counts/counts.sum(), 'r-', lw = 2, label = 'Distribution')        \n",
    "        \n",
    "        axes[row, col].set_title(f'Distribution of {title} ')\n",
    "        axes[row, col].set_xlabel( f'{title} ({unit})')\n",
    "        axes[row, col].set_ylabel('Share')\n",
    "        axes[row, col].grid(True)\n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    # Plot 5: Correlation Analysis\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(15, 15))\n",
    "    fig.suptitle('Correlation Analysis - of Raw Measurements Correlations', y=1.02, fontsize=16)\n",
    "\n",
    "    # Original correlations\n",
    "    sns.heatmap(\n",
    "        df[measurements.keys()].corr(),\n",
    "        annot=True,\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        fmt='.2f',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "    ' !!! SOURCE !!!'\n",
    "    # Plot 6 Hexbins\n",
    "    measure = list(measurements.keys())\n",
    "    pairs = [(measure[i], measure[j]) for i in range(len(measure)) for j in range(i + 1, len(measure))]\n",
    "\n",
    "    # Number of subplots\n",
    "    n_rows = 7\n",
    "    n_cols = 3\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    fig.suptitle('Hexbins of Raw Measurements', y=1.02, fontsize=16)\n",
    "    axes = axes.flatten()  # Flatten the axes to make indexing easier\n",
    "\n",
    "    # Loop over the pairs\n",
    "    for i, (measure1, measure2) in enumerate(pairs):\n",
    "        ax = axes[i]\n",
    "        x = df[measure1]\n",
    "        y = df[measure2]\n",
    "        \n",
    "        # Plot hexbin\n",
    "        hb = ax.hexbin(x, y, gridsize=30, cmap='viridis')\n",
    "        ax.set_xlabel(measure1)\n",
    "        ax.set_ylabel(measure2)\n",
    "        ax.set_title(f'Hexbin: {measure1} vs {measure2}')\n",
    "        # Add color bar\n",
    "        fig.colorbar(hb, ax=ax)\n",
    "        \n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "\n",
    "    # Plot 7: Scatter Matrix\n",
    "    # Get data without duplicates by taking mean for each timestamp\n",
    "    df_plot = df.groupby(df.index)[measure].mean()\n",
    "    try:\n",
    "        pp = sns.pairplot(data=df_plot,\n",
    "                            diag_kind='kde',\n",
    "                            plot_kws={'alpha': 0.5, 's': 20},\n",
    "                            height = 6)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create scatter matrix plot: {str(e)}\")\n",
    "\n",
    "    fig = pp.figure\n",
    "    fig.suptitle('Scatter Matrix of Raw Measurements', y=1.02, fontsize=16)\n",
    "    \n",
    "    #----------------------------------------------\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    temp_name = f\"{out_dir}{out_name}_plot_{image_nr}.png\"\n",
    "    fig.savefig(temp_name, dpi=200, bbox_inches='tight')\n",
    "    image_names.append(temp_name)\n",
    "    image_nr += 1\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    #save_image(image_names, out_dir, out_name)\n",
    "    if not show_plots:\n",
    "        plt.close(\"all\")\n",
    "\n",
    "\n",
    "# testing visu_raw_data(True, None, None,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function called with a file: ./data_filtered/system-1.csv\n",
      "Function called with a file: ./data_filtered/system-2.csv\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    visu_raw_data(False, pathFilter,file,None)\n",
    "    plt.close(\"all\") #for safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Raw & Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_system_data(show_plots: bool, file_dir: str, file_name: str, df_arg: pd.DataFrame = None):\n",
    "    \"\"\"Preprocess system performance data.\n",
    "    Cleans data with:\n",
    "          * Invalid values removed\n",
    "          * Duplicates handled\n",
    "          * Outliers removed\n",
    "          * Missing values interpolated\n",
    "    Parameters\n",
    "    ----------\n",
    "    show_plots: bool\n",
    "        Just output files or display in notebook\n",
    "    file_dir : str\n",
    "        Path to the CSV data file location (directory)\n",
    "    file_name : str\n",
    "        Name of the specified CSV file\n",
    "    \n",
    "    \n",
    "    optional\n",
    "    df_arg: pd.DataFrame\n",
    "        output from load_system_data()\n",
    "\n",
    "    Additional outputs\n",
    "    saves visualized data into dir \"./visu_raw\" by calling save_image() and cleaning temp-files with delete_images()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO !! -----------------------\n",
    "    \n",
    "    # Check DataFrame was passed\n",
    "    if isinstance(df_arg, pd.DataFrame):\n",
    "        df = df_arg\n",
    "        # File name and path -> pd used => no identifier => using \"./\" \n",
    "        out_dir = \"./\"\n",
    "        out_name = \"Visu_output_noident\"\n",
    "        print(\"Function called with a DataFrame.\")\n",
    "    else:\n",
    "        # Attempt to read the DataFrame from file\n",
    "        try:\n",
    "            file_path = file_dir + file_name\n",
    "            df = pd.read_csv(file_path, delimiter = \",\",usecols=[\"datetime\",\"load-15m\",\"memory_used_pct\",\"cpu-user\",\"cpu-system\",\"sys-thermal\",\"sys-interrupt-rate\",\"server-up\",\"disk-io-time\"])\n",
    "            print(f\"Function called with a file: {file_path}\")\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df.set_index('datetime', inplace=True)\n",
    "            # File name and path -> path used => use identifier \n",
    "            out_dir = pathVisuRaw\n",
    "            out_name = file_name.replace('.csv', '')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the file: {e}\")\n",
    "            return None\n",
    "    measurements = {\n",
    "        \"load-15m\": ('load-15m', '%'),\n",
    "        \"memory_used_pct\": ('memory_used_pct', '%'),\n",
    "        \"cpu-user\": ('cpu-user', 'delta-s'),\n",
    "        \"cpu-system\": ('cpu-system', 'delta-s'),\n",
    "        \"sys-thermal\": ('sys-thermal', 'avg delta-°C/min'),\n",
    "        \"sys-interrupt-rate\": ('sys-interrupt-rate', 'delta-s'),\n",
    "        \"disk-io-time\": ('disk-io-time', 'delta-s')\n",
    "        #,\"server-up\": ('server-sup', '')\n",
    "    }\n",
    "\n",
    "    # Store original data\n",
    "    df_original = df.copy()\n",
    "   \n",
    "   \n",
    "    # Define valid ranges\n",
    "    valid_ranges = {\n",
    "        'load-15m': (0, 0.5),           # System load\n",
    "        'memory_used_pct': (0, 100),   # Percentage\n",
    "        'cpu-user': (0.0, 2.0),            # Rate of change in CPU time\n",
    "        'sys-thermal': (-10, 10),      # Rate of change in °C\n",
    "        'server-up': (0, float('inf')) # Server availability\n",
    "    }\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # 1. Handle invalid values\n",
    "\n",
    "    for column, (min_val, max_val) in valid_ranges.items():\n",
    "        invalid_mask = (df[column] < min_val) | (df[column] > max_val)\n",
    "        print(f\"Removing {invalid_mask.sum()} invalid values from {column}\")\n",
    "        df.loc[invalid_mask, column] = np.nan\n",
    "    \n",
    "    # 2. Handle duplicates\n",
    "    print(\"Handling duplicate timestamps...\")\n",
    "    df = df.groupby(['datetime', 'server-up']).agg({\n",
    "        'load-15m': 'mean',\n",
    "        'memory_used_pct': 'mean',\n",
    "        'cpu-user': 'mean',\n",
    "        'sys-thermal': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 3. Remove outliers\n",
    "    def remove_outliers_iqr(df, column):\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        valid_mask = (df[column] >= Q1 - 1.5*IQR) & (df[column] <= Q3 + 1.5*IQR)\n",
    "        invalid_count = (~valid_mask).sum()\n",
    "        print(f\"Removing {invalid_count} outliers from {column}\")\n",
    "        return df[column].where(valid_mask, np.nan)\n",
    "    \n",
    "    for column in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal']:\n",
    "        df[column] = remove_outliers_iqr(df, column)\n",
    "    \n",
    "    # 4. Handle missing values\n",
    "\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    print(f\"Missing values before handling: \\n{df.isnull().sum()}\")\n",
    "    \n",
    "    # Handle missing values by sensor\n",
    "    df_cleaned = pd.DataFrame()\n",
    "    for sensor in sorted(df['server-up'].unique()):\n",
    "        print(f\"Processing sensor {sensor}...\")\n",
    "        sensor_data = df[df['server-up'] == sensor].copy()\n",
    "        \n",
    "        # Ensure datetime column is a DatetimeIndex\n",
    "        sensor_data['datetime'] = pd.to_datetime(sensor_data['datetime'])\n",
    "        sensor_data.set_index('datetime', inplace=True)\n",
    "        \n",
    "        # Resample to regular intervals (e.g., 5-minute intervals)\n",
    "        sensor_data = sensor_data.resample('5min').mean() # 5T->5min\n",
    "        \n",
    "        # Interpolate missing values\n",
    "        for column in ['load-15m', 'memory_used_pct', 'cpu-user', 'sys-thermal']:\n",
    "            sensor_data[column] = sensor_data[column].interpolate(\n",
    "                method='linear',\n",
    "                limit=4 \n",
    "            )\n",
    "\n",
    "    # Add back the sensor ID\n",
    "        sensor_data['server-up'] = sensor\n",
    "        \n",
    "        # Append to cleaned dataframe\n",
    "        df_cleaned = pd.concat([df_cleaned, sensor_data], sort=False)\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df_cleaned.sort_index(inplace=True)\n",
    "    \n",
    "    print(f\"Missing values after handling: \\n{df_cleaned.isnull().sum()}\")\n",
    "    \n",
    "    print(f\"\\nOriginal shape: {df_original.shape}\")\n",
    "    print(f\"Cleaned shape: {df_cleaned.shape}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    return df_cleaned, df_original\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
